# Backend Security & Architecture Checklist

> **Audience**: Ã‰quipe d'ingÃ©nieurs confirmÃ©s  
> **Stack**: FastAPI + PostgreSQL + JWT + Multi-tenant SaaS  
> **Version**: 1.0  

---

## Table des matiÃ¨res

1. [SÃ©curitÃ© - Authentification](#1-sÃ©curitÃ©---authentification)
2. [SÃ©curitÃ© - Tokens JWT](#2-sÃ©curitÃ©---tokens-jwt)
3. [SÃ©curitÃ© - Mots de passe](#3-sÃ©curitÃ©---mots-de-passe)
4. [SÃ©curitÃ© - Anti-bruteforce & Rate Limiting](#4-sÃ©curitÃ©---anti-bruteforce--rate-limiting)
5. [SÃ©curitÃ© - MFA](#5-sÃ©curitÃ©---mfa)
6. [SÃ©curitÃ© - Sessions](#6-sÃ©curitÃ©---sessions)
7. [SÃ©curitÃ© - API Keys](#7-sÃ©curitÃ©---api-keys)
8. [SÃ©curitÃ© - Headers HTTP](#8-sÃ©curitÃ©---headers-http)
9. [SÃ©curitÃ© - Input Validation](#9-sÃ©curitÃ©---input-validation)
10. [Architecture - Structure projet](#10-architecture---structure-projet)
11. [Architecture - Middleware Stack](#11-architecture---middleware-stack)
12. [Architecture - Dependency Injection](#12-architecture---dependency-injection)
13. [Architecture - Service Layer](#13-architecture---service-layer)
14. [Architecture - Repository Pattern](#14-architecture---repository-pattern)
15. [Architecture - Exception Handling](#15-architecture---exception-handling)
16. [Multi-tenant](#16-multi-tenant)
17. [Base de donnÃ©es - Schema](#17-base-de-donnÃ©es---schema)
18. [Base de donnÃ©es - Performance](#18-base-de-donnÃ©es---performance)
19. [Base de donnÃ©es - Maintenance](#19-base-de-donnÃ©es---maintenance)
20. [ObservabilitÃ© - Logging](#20-observabilitÃ©---logging)
21. [ObservabilitÃ© - Metrics](#21-observabilitÃ©---metrics)
22. [ObservabilitÃ© - Tracing](#22-observabilitÃ©---tracing)
23. [Performance](#23-performance)
24. [Tests](#24-tests)
25. [CI/CD](#25-cicd)
26. [Documentation](#26-documentation)
27. [Compliance & Audit](#27-compliance--audit)
28. [Operations](#28-operations)

---

## 1. SÃ©curitÃ© - Authentification

### 1.1 Flow Login

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Constant-time comparison** | ðŸ”´ CRITICAL | Utiliser `secrets.compare_digest()` pour comparer hashes, jamais `==` |
| [x] | **User enumeration prevention** | ðŸ”´ CRITICAL | MÃªme message d'erreur que l'user existe ou non: "Invalid credentials" |
| [x] | **Timing attack prevention** | ðŸ”´ CRITICAL | Hasher un DUMMY_HASH si user inexistant pour garder timing constant |
| [x] | **Credentials in body only** | ðŸ”´ CRITICAL | Jamais de password dans URL, query params, ou headers custom |
| [x] | **HTTPS only** | ðŸ”´ CRITICAL | Refuser HTTP en production, mÃªme pour /health |
| [x] | **Login response unifiÃ©** | ðŸŸ  HIGH | MÃªme schema LoginResponse que MFA requis ou non |
| [x] | **Lowercase email** | ðŸŸ  HIGH | Normaliser email en lowercase avant lookup |
| [x] | **Trim whitespace** | ðŸŸ  HIGH | Strip espaces sur email/username |

```python
# âœ… Implementation correcte
DUMMY_HASH = "$2b$12$LQv3c1yqBWVHxkd0LHAkCOYz6TtxMQJqhN8/X4.V" # Precomputed

async def authenticate(email: str, password: str) -> User:
    email = email.lower().strip()
    user = await user_repo.get_by_email(email)
    
    # Timing constant: hash mÃªme si user inexistant
    hash_to_verify = user.password_hash if user else DUMMY_HASH
    password_valid = secrets.compare_digest(
        verify_password(password, hash_to_verify).encode(),
        b"valid"  # ou votre logique
    )
    # Alternative avec passlib:
    # password_valid = pwd_context.verify(password, hash_to_verify)
    
    if not user or not password_valid:
        # Log failed attempt AVANT de raise
        await audit.log("login_failed", identifier=email)
        raise InvalidCredentials()  # Message gÃ©nÃ©rique
    
    return user
```

### 1.2 Logout

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Blacklist access token** | ðŸ”´ CRITICAL | InsÃ©rer JTI dans `revoked_tokens` |
| [x] | **RÃ©voquer session** | ðŸ”´ CRITICAL | `sessions.revoked_at = NOW()` |
| [x] | **Invalider tous refresh tokens** | ðŸ”´ CRITICAL | Via CASCADE ou update explicite |
| [x] | **Logout all devices** | ðŸŸ  HIGH | Endpoint pour rÃ©voquer toutes les sessions sauf courante |
| [N/A] | **Clear cookies** | ðŸŸ  HIGH | N/A - Bearer tokens utilisÃ©s, pas de cookies |

### 1.3 Password Reset

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Token usage unique** | ðŸ”´ CRITICAL | Marquer `used_at` aprÃ¨s utilisation |
| [x] | **Expiration courte** | ðŸ”´ CRITICAL | 1 heure max |
| [x] | **Invalider sessions existantes** | ðŸ”´ CRITICAL | Forcer re-login aprÃ¨s reset |
| [x] | **Rate limit requests** | ðŸ”´ CRITICAL | Max 3 demandes/heure/email |
| [x] | **Token cryptographiquement sÃ»r** | ðŸ”´ CRITICAL | `secrets.token_urlsafe(32)` minimum |
| [x] | **Hasher le token en DB** | ðŸŸ  HIGH | Stocker SHA-256, pas le token brut |
| [x] | **Email gÃ©nÃ©rique** | ðŸŸ  HIGH | "If this email exists, you'll receive..." |
| [x] | **Log password changes** | ðŸŸ  HIGH | AuditService.log_action("user.password_change") |

---

## 2. SÃ©curitÃ© - Tokens JWT

### 2.1 GÃ©nÃ©ration

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Secret â‰¥ 256 bits** | ðŸ”´ CRITICAL | Minimum 32 caractÃ¨res alÃ©atoires |
| [x] | **Secret unique par env** | ðŸ”´ CRITICAL | Dev â‰  Staging â‰  Prod |
| [x] | **Validation secret au startup** | ðŸ”´ CRITICAL | Crash si secret = valeur par dÃ©faut |
| [x] | **Algorithm explicite** | ðŸ”´ CRITICAL | Toujours spÃ©cifier `algorithm="HS256"` ou RS256 |
| [x] | **JTI unique** | ðŸ”´ CRITICAL | UUID v4 pour chaque token |
| [x] | **Claims minimaux** | ðŸŸ  HIGH | sub, tenant_id, type, exp, iat, jti - pas de donnÃ©es sensibles |
| [ ] | **Issuer (iss)** | ðŸŸ¡ MEDIUM | Identifier l'Ã©metteur |
| [ ] | **Audience (aud)** | ðŸŸ¡ MEDIUM | Identifier le destinataire |

```python
# âœ… Settings avec validation
class Settings(BaseSettings):
    JWT_SECRET: str
    JWT_ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 15
    REFRESH_TOKEN_EXPIRE_DAYS: int = 7
    
    _DANGEROUS_DEFAULTS = ["changeme", "secret", "CHANGE_IN_PRODUCTION"]
    
    @validator("JWT_SECRET")
    def validate_jwt_secret(cls, v):
        if v in cls._DANGEROUS_DEFAULTS:
            raise ValueError("JWT_SECRET must be changed from default!")
        if len(v) < 32:
            raise ValueError("JWT_SECRET must be at least 32 characters!")
        return v
    
    def validate_production_secrets(self):
        """Call this at startup in production"""
        if self.ENV == "production":
            assert self.JWT_SECRET not in self._DANGEROUS_DEFAULTS
```

### 2.2 Validation

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **VÃ©rifier signature** | ðŸ”´ CRITICAL | DÃ©coder avec verify=True |
| [x] | **VÃ©rifier expiration** | ðŸ”´ CRITICAL | Rejeter si exp < now |
| [x] | **VÃ©rifier type** | ðŸ”´ CRITICAL | access â‰  refresh â‰  mfa_session |
| [x] | **Check blacklist** | ðŸ”´ CRITICAL | Lookup JTI dans `revoked_tokens` |
| [x] | **Check session active** | ðŸ”´ CRITICAL | Si session_id prÃ©sent, vÃ©rifier non rÃ©voquÃ©e |
| [x] | **Valider sub format** | ðŸ”´ CRITICAL | Doit Ãªtre int > 0 |
| [x] | **Cross-tenant validation** | ðŸ”´ CRITICAL | token.tenant_id == user.tenant_id |
| [x] | **Rejeter algorithm none** | ðŸ”´ CRITICAL | PyJWT le fait par dÃ©faut, mais vÃ©rifier |
| [ ] | **Clock skew tolerance** | ðŸŸ¡ MEDIUM | Â±30 secondes pour exp/iat |

```python
# âœ… Validation complÃ¨te
def decode_and_validate_token(token: str, expected_type: str) -> dict:
    try:
        payload = jwt.decode(
            token,
            settings.JWT_SECRET,
            algorithms=[settings.JWT_ALGORITHM],
            options={
                "require": ["sub", "exp", "type", "jti"],
                "verify_exp": True,
            }
        )
    except jwt.ExpiredSignatureError:
        raise HTTPException(401, "Token expired")
    except jwt.InvalidTokenError:
        raise HTTPException(401, "Invalid token")
    
    # Type check
    if payload.get("type") != expected_type:
        raise HTTPException(401, f"Expected {expected_type} token")
    
    # Sub validation
    sub = payload.get("sub")
    if sub is None:
        raise HTTPException(401, "Missing subject")
    try:
        user_id = int(sub)
        if user_id <= 0:
            raise ValueError()
    except (ValueError, TypeError):
        raise HTTPException(401, "Invalid subject")
    
    return payload
```

### 2.3 DurÃ©es de vie

| Token Type | DurÃ©e | Justification |
|------------|-------|---------------|
| Access Token | 15 minutes | Court = moins de risque si volÃ© |
| Refresh Token | 7 jours | UX vs sÃ©curitÃ© |
| MFA Session | 5 minutes | Juste le temps de taper le code |
| Password Reset | 1 heure | Assez pour check email |
| Email Verification | 24 heures | DÃ©lais email possibles |
| API Key | 1 an ou permanent | Avec rotation recommandÃ©e |

### 2.4 Refresh Token Rotation

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Rotation Ã  chaque usage** | ðŸ”´ CRITICAL | Ancien invalidÃ©, nouveau Ã©mis |
| [x] | **Stocker hash, pas token** | ðŸ”´ CRITICAL | SHA-256 du token en DB |
| [x] | **Tracking lineage** | ðŸ”´ CRITICAL | `replaced_by_jti` pour tracer |
| [x] | **Replay detection** | ðŸ”´ CRITICAL | Si token dÃ©jÃ  used â†’ rÃ©voquer TOUTE la session |
| [x] | **Validate session on refresh** | ðŸ”´ CRITICAL | Session doit Ãªtre active |
| [x] | **Absolute expiry** | ðŸŸ  HIGH | Refresh max 30 jours mÃªme avec rotation - Session.absolute_expiry |

```python
# âœ… Refresh avec rotation et replay detection
async def refresh_tokens(refresh_token: str) -> TokenPair:
    token_hash = hashlib.sha256(refresh_token.encode()).hexdigest()
    
    stored = await token_repo.get_by_hash(token_hash)
    if not stored:
        raise HTTPException(401, "Invalid refresh token")
    
    # Replay detection
    if stored.used_at is not None:
        # Token already used = stolen token replay attack!
        await session_service.revoke_session(stored.session_id)
        await audit.log("replay_attack_detected", session_id=stored.session_id)
        raise HTTPException(401, "Token reuse detected - session revoked")
    
    # Expiration check
    if stored.expires_at < datetime.utcnow():
        raise HTTPException(401, "Refresh token expired")
    
    # Session check
    session = await session_repo.get(stored.session_id)
    if not session or session.revoked_at:
        raise HTTPException(401, "Session revoked")
    
    # Mark as used
    await token_repo.mark_used(stored.jti)
    
    # Generate new pair
    new_access = create_access_token(session.user_id, session.tenant_id)
    new_refresh = create_refresh_token(session.id)
    
    # Link old to new
    await token_repo.set_replaced_by(stored.jti, new_refresh.jti)
    
    return TokenPair(access=new_access, refresh=new_refresh)
```

---

## 3. SÃ©curitÃ© - Mots de passe

### 3.1 Hashing

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **bcrypt ou Argon2id** | ðŸ”´ CRITICAL | Jamais MD5, SHA1, SHA256 seul |
| [x] | **Cost factor appropriÃ©** | ðŸ”´ CRITICAL | bcrypt cost â‰¥ 12, Argon2 memory â‰¥ 64MB |
| [x] | **Salt unique auto** | ðŸ”´ CRITICAL | bcrypt/Argon2 le font automatiquement |
| [ ] | **Upgrade hash on login** | ðŸŸ¡ MEDIUM | Si ancien algo, re-hash avec nouveau |

```python
# âœ… Configuration passlib
from passlib.context import CryptContext

pwd_context = CryptContext(
    schemes=["bcrypt"],
    deprecated="auto",
    bcrypt__rounds=12,  # Adjust based on server performance
)

def hash_password(password: str) -> str:
    return pwd_context.hash(password)

def verify_password(plain: str, hashed: str) -> bool:
    return pwd_context.verify(plain, hashed)

def needs_rehash(hashed: str) -> bool:
    return pwd_context.needs_update(hashed)
```

### 3.2 Validation

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Longueur minimum 8** | ðŸ”´ CRITICAL | NIST recommande â‰¥8 |
| [x] | **Longueur maximum 128** | ðŸ”´ CRITICAL | PrÃ©venir DoS via bcrypt |
| [x] | **ComplexitÃ©** | ðŸŸ  HIGH | 1 maj, 1 min, 1 chiffre, 1 special |
| [x] | **Pas dans liste compromis** | ðŸŸ  HIGH | Check contre HaveIBeenPwned ou liste locale |
| [x] | **Pas username/email** | ðŸŸ  HIGH | Password â‰  identifiant |
| [x] | **Unicode supportÃ©** | ðŸŸ¡ MEDIUM | Permettre caractÃ¨res non-ASCII |
| [x] | **No password hints** | ðŸŸ¡ MEDIUM | Jamais de "indice" stockÃ© |

```python
# âœ… Validation Pydantic
import re
from pydantic import BaseModel, validator

class PasswordMixin:
    @validator("password")
    def validate_password(cls, v):
        if len(v) < 8:
            raise ValueError("Password must be at least 8 characters")
        if len(v) > 128:
            raise ValueError("Password must be at most 128 characters")
        if not re.search(r"[A-Z]", v):
            raise ValueError("Password must contain uppercase letter")
        if not re.search(r"[a-z]", v):
            raise ValueError("Password must contain lowercase letter")
        if not re.search(r"\d", v):
            raise ValueError("Password must contain digit")
        if not re.search(r"[!@#$%^&*(),.?\":{}|<>]", v):
            raise ValueError("Password must contain special character")
        return v

class RegisterRequest(BaseModel, PasswordMixin):
    email: str
    password: str
```

---

## 4. SÃ©curitÃ© - Anti-bruteforce & Rate Limiting

### 4.1 Rate Limiting Global

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Middleware global** | ðŸ”´ CRITICAL | Avant toute logique |
| [x] | **Backend Redis** | ðŸ”´ CRITICAL | Pas in-memory en multi-instance |
| [x] | **Sliding window** | ðŸŸ  HIGH | Plus juste que fixed window |
| [x] | **DiffÃ©rent par endpoint** | ðŸŸ  HIGH | /login plus strict que /users |
| [x] | **Headers X-RateLimit-*** | ðŸŸ¡ MEDIUM | Informer le client |
| [x] | **429 Too Many Requests** | ðŸŸ  HIGH | Status code correct + Retry-After |

```python
# âœ… Rate limit middleware
from fastapi import Request, HTTPException
from redis.asyncio import Redis
import time

class RateLimitMiddleware:
    def __init__(self, redis: Redis, default_limit: int = 100, window: int = 60):
        self.redis = redis
        self.default_limit = default_limit
        self.window = window
        
        # Limites par endpoint
        self.endpoint_limits = {
            "/api/v1/auth/login": 5,
            "/api/v1/auth/refresh": 30,
            "/api/v1/mfa/verify": 5,
            "/api/v1/mfa/recovery/verify": 3,
            "/api/v1/auth/password/reset": 3,
        }
    
    async def __call__(self, request: Request, call_next):
        # Key based on IP + endpoint
        ip = request.client.host
        path = request.url.path
        key = f"ratelimit:{ip}:{path}"
        
        limit = self.endpoint_limits.get(path, self.default_limit)
        
        # Sliding window counter
        now = time.time()
        pipe = self.redis.pipeline()
        pipe.zremrangebyscore(key, 0, now - self.window)
        pipe.zadd(key, {str(now): now})
        pipe.zcard(key)
        pipe.expire(key, self.window)
        results = await pipe.execute()
        
        request_count = results[2]
        
        if request_count > limit:
            raise HTTPException(
                status_code=429,
                detail="Too many requests",
                headers={
                    "Retry-After": str(self.window),
                    "X-RateLimit-Limit": str(limit),
                    "X-RateLimit-Remaining": "0",
                    "X-RateLimit-Reset": str(int(now + self.window)),
                }
            )
        
        response = await call_next(request)
        response.headers["X-RateLimit-Limit"] = str(limit)
        response.headers["X-RateLimit-Remaining"] = str(max(0, limit - request_count))
        return response
```

### 4.2 Anti-bruteforce Login

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Tracking par identifier** | ðŸ”´ CRITICAL | Email/username, fenÃªtre 15 min |
| [x] | **Tracking par IP** | ðŸ”´ CRITICAL | FenÃªtre 1 heure |
| [x] | **Escalade progressive** | ðŸ”´ CRITICAL | CAPTCHA â†’ Delay â†’ Lock â†’ Alert |
| [x] | **Log toutes tentatives** | ðŸ”´ CRITICAL | Table `login_attempts` |
| [ ] | **Reset on success** | ðŸŸ  HIGH | Ou pas - philosophie diffÃ©rente |
| [~] | **Notification user** | ðŸŸ  HIGH | Email si tentatives suspectes - Infrastructure SMTP requise |
| [x] | **Alert admin** | ðŸŸ  HIGH | Slack/PagerDuty si seuil atteint |

**Seuils recommandÃ©s:**

| Par identifier | Action |
|----------------|--------|
| 3 Ã©checs | CAPTCHA |
| 5 Ã©checs | DÃ©lai 30s entre tentatives |
| 10 Ã©checs | Compte verrouillÃ© 15 min |
| 20 Ã©checs | Compte verrouillÃ© 1h |
| 50 Ã©checs | Lock + Alerte admin |

| Par IP | Action |
|--------|--------|
| 20 Ã©checs | CAPTCHA pour cette IP |
| 50 Ã©checs | Rate limit 1 req/10s |
| 100 Ã©checs | IP bloquÃ©e 1h |
| 500 Ã©checs | IP bloquÃ©e 24h + Alerte |

### 4.3 CAPTCHA

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **reCAPTCHA v3 ou hCaptcha** | ðŸŸ  HIGH | Invisible, score-based |
| [x] | **Validation cÃ´tÃ© serveur** | ðŸ”´ CRITICAL | Jamais faire confiance au client |
| [x] | **Timeout validation** | ðŸŸ  HIGH | Token CAPTCHA expire vite |
| [ ] | **Fallback si service down** | ðŸŸ¡ MEDIUM | DÃ©grader gracieusement |

---

## 5. SÃ©curitÃ© - MFA

### 5.1 TOTP

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Secret chiffrÃ© en DB** | ðŸ”´ CRITICAL | AES-256-GCM, jamais plaintext |
| [x] | **QR code Ã©phÃ©mÃ¨re** | ðŸ”´ CRITICAL | Ne pas stocker l'image |
| [x] | **VÃ©rifier code avant enable** | ðŸ”´ CRITICAL | Prouver que l'app est configurÃ©e |
| [x] | **TolÃ©rance Â±1 window** | ðŸŸ  HIGH | 30s avant/aprÃ¨s pour clock drift |
| [x] | **Anti-replay** | ðŸ”´ CRITICAL | Un code ne peut Ãªtre utilisÃ© qu'une fois |
| [x] | **Rate limit verify** | ðŸ”´ CRITICAL | Max 5/min (10^6 combinaisons) |

```python
# âœ… TOTP verification avec anti-replay
import pyotp
from datetime import datetime, timedelta

async def verify_totp(user_id: int, code: str) -> bool:
    mfa = await mfa_repo.get_secret(user_id)
    if not mfa or not mfa.enabled:
        return False
    
    # Decrypt secret
    secret = decrypt_aes_gcm(mfa.secret, settings.ENCRYPTION_KEY)
    
    totp = pyotp.TOTP(secret)
    
    # Check with Â±1 window tolerance
    if not totp.verify(code, valid_window=1):
        return False
    
    # Anti-replay: check last used code time
    # TOTP changes every 30s, so store timestamp of last valid code
    current_window = int(datetime.utcnow().timestamp() // 30)
    if mfa.last_totp_window and mfa.last_totp_window >= current_window:
        # Same code already used in this window
        return False
    
    # Update last used
    await mfa_repo.update_last_used(user_id, current_window)
    
    return True
```

### 5.2 Recovery Codes

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **8-10 codes gÃ©nÃ©rÃ©s** | ðŸŸ  HIGH | Balance sÃ©curitÃ©/praticitÃ© |
| [x] | **Haute entropie** | ðŸ”´ CRITICAL | 8+ chars alphanumÃ©riques |
| [x] | **HashÃ©s en DB** | ðŸ”´ CRITICAL | bcrypt cost 10 |
| [x] | **Usage unique** | ðŸ”´ CRITICAL | Marquer `used_at` aprÃ¨s utilisation |
| [x] | **Afficher une seule fois** | ðŸ”´ CRITICAL | User doit les sauvegarder |
| [x] | **RÃ©gÃ©nÃ©ration invalide anciens** | ðŸ”´ CRITICAL | Delete all avant insert new |
| [x] | **Rate limit strict** | ðŸ”´ CRITICAL | Max 3/min |
| [~] | **Alert on use** | ðŸŸ  HIGH | Notifier user par email - Infrastructure SMTP requise |

### 5.3 Flow MFA 2 Ã©tapes

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **MFA Session Token sÃ©parÃ©** | ðŸ”´ CRITICAL | Type "mfa_session", pas d'accÃ¨s API |
| [x] | **Expiration 5 minutes** | ðŸ”´ CRITICAL | Juste le temps de taper |
| [ ] | **Ne pas rÃ©vÃ©ler MFA status** | ðŸŸ  HIGH | MÃªme response time |
| [x] | **Forcer MFA aprÃ¨s compromission** | ðŸŸ  HIGH | User.mfa_required + force_mfa_required() |

---

## 6. SÃ©curitÃ© - Sessions

### 6.1 Gestion

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **UUID v4 pour session ID** | ðŸ”´ CRITICAL | Non prÃ©dictible |
| [x] | **Tracking IP + User-Agent** | ðŸŸ  HIGH | DÃ©tecter hijacking |
| [x] | **last_seen_at update** | ðŸŸ  HIGH | Timeout inactivitÃ© |
| [x] | **Revocation immÃ©diate** | ðŸ”´ CRITICAL | revoked_at = NOW() |
| [x] | **Cascade sur tokens** | ðŸ”´ CRITICAL | Refresh tokens invalidÃ©s |
| [x] | **List sessions endpoint** | ðŸŸ  HIGH | User peut voir ses sessions |
| [x] | **Revoke other sessions** | ðŸŸ  HIGH | SÃ©curitÃ© post-compromission |
| [ ] | **Max sessions par user** | ðŸŸ¡ MEDIUM | Ex: 5 max, rÃ©voquer plus ancienne |

### 6.2 Validation

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Check sur chaque requÃªte** | ðŸ”´ CRITICAL | Via access token session_id |
| [x] | **Ou check sur refresh only** | ðŸŸ  HIGH | Moins strict, meilleure perf |
| [ ] | **IP change detection** | ðŸŸ¡ MEDIUM | Alerter ou invalider |
| [ ] | **Device fingerprint** | ðŸŸ¡ MEDIUM | User-Agent + autres signaux |

---

## 7. SÃ©curitÃ© - API Keys

### 7.1 GÃ©nÃ©ration

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **PrÃ©fixe identifiable** | ðŸŸ  HIGH | Ex: `sk_live_`, `sk_test_` |
| [x] | **Haute entropie** | ðŸ”´ CRITICAL | `secrets.token_urlsafe(32)` |
| [x] | **Afficher une seule fois** | ðŸ”´ CRITICAL | Pas de "show key" ensuite |
| [x] | **Hasher en DB** | ðŸ”´ CRITICAL | SHA-256 ou Argon2 |
| [x] | **Scopes limitÃ©s** | ðŸŸ  HIGH | Least privilege principle - APIKeyScopes + has_scope() |
| [x] | **Expiration optionnelle** | ðŸŸ  HIGH | Recommander 1 an max |

### 7.2 Validation

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Constant-time compare** | ðŸ”´ CRITICAL | Via hash comparison |
| [x] | **Check revoked_at** | ðŸ”´ CRITICAL | Key peut Ãªtre rÃ©voquÃ©e |
| [x] | **Check expires_at** | ðŸ”´ CRITICAL | Key peut expirer |
| [x] | **Tenant isolation** | ðŸ”´ CRITICAL | Key liÃ©e Ã  un tenant |
| [x] | **Log usage** | ðŸŸ  HIGH | Table `api_key_usage` + APIKeyUsageRepository |
| [x] | **Update last_used_at** | ðŸŸ  HIGH | DÃ©tecter keys inutilisÃ©es |
| [x] | **Rate limit par key** | ðŸŸ  HIGH | check_rate_limit() + enforce_rate_limit() |

---

## 8. SÃ©curitÃ© - Headers HTTP

### 8.1 Response Headers

| # | Header | Valeur | PrioritÃ© |
|---|--------|--------|----------|
| [x] | `Strict-Transport-Security` | `max-age=31536000; includeSubDomains` | ðŸ”´ CRITICAL |
| [x] | `X-Content-Type-Options` | `nosniff` | ðŸ”´ CRITICAL |
| [x] | `X-Frame-Options` | `DENY` | ðŸ”´ CRITICAL |
| [x] | `Content-Security-Policy` | Selon app | ðŸŸ  HIGH |
| [x] | `X-XSS-Protection` | `1; mode=block` | ðŸŸ¡ MEDIUM (deprecated) |
| [x] | `Referrer-Policy` | `strict-origin-when-cross-origin` | ðŸŸ¡ MEDIUM |
| [x] | `Permissions-Policy` | Selon besoins | ðŸŸ¡ MEDIUM |
| [x] | `Cache-Control` | `no-store` pour auth endpoints | ðŸŸ  HIGH |

```python
# âœ… Security headers middleware
from starlette.middleware.base import BaseHTTPMiddleware

class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        response = await call_next(request)
        
        response.headers["Strict-Transport-Security"] = "max-age=31536000; includeSubDomains"
        response.headers["X-Content-Type-Options"] = "nosniff"
        response.headers["X-Frame-Options"] = "DENY"
        response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
        
        # No cache for auth endpoints
        if "/auth/" in request.url.path:
            response.headers["Cache-Control"] = "no-store"
        
        return response
```

### 8.2 CORS

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Whitelist explicite** | ðŸ”´ CRITICAL | Jamais `*` en prod avec credentials |
| [x] | **Origins depuis config** | ðŸŸ  HIGH | Pas hardcodÃ© |
| [x] | **Credentials=true si cookies** | ðŸŸ  HIGH | Sinon cookies ignorÃ©s |
| [ ] | **Preflight cache** | ðŸŸ¡ MEDIUM | `max_age=3600` |

```python
# âœ… CORS configuration
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,  # ["https://app.example.com"]
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "PATCH"],
    allow_headers=["Authorization", "Content-Type", "X-Tenant-ID", "X-Request-ID"],
    expose_headers=["X-Request-ID", "X-RateLimit-Remaining"],
    max_age=3600,
)
```

---

## 9. SÃ©curitÃ© - Input Validation

### 9.1 Pydantic Schemas

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **extra = "forbid"** | ðŸ”´ CRITICAL | Rejeter champs inconnus |
| [x] | **Types stricts** | ðŸ”´ CRITICAL | `StrictStr`, `StrictInt` si nÃ©cessaire |
| [x] | **Longueurs max** | ðŸ”´ CRITICAL | `max_length` sur tous les strings |
| [x] | **Regex validation** | ðŸŸ  HIGH | Emails, phones, etc. |
| [x] | **Enum pour valeurs fixes** | ðŸŸ  HIGH | Pas de strings libres pour status, types |
| [x] | **Validators custom** | ðŸŸ  HIGH | Logique mÃ©tier dans validators |

```python
# âœ… Strict schema example
from pydantic import BaseModel, Field, EmailStr, validator
from typing import Optional
from enum import Enum

class UserRole(str, Enum):
    ADMIN = "admin"
    USER = "user"
    VIEWER = "viewer"

class CreateUserRequest(BaseModel):
    email: EmailStr
    password: str = Field(..., min_length=8, max_length=128)
    name: str = Field(..., min_length=1, max_length=100)
    role: UserRole = UserRole.USER
    
    class Config:
        extra = "forbid"  # Reject unknown fields
        str_strip_whitespace = True  # Auto-strip
    
    @validator("name")
    def validate_name(cls, v):
        if not v.replace(" ", "").isalpha():
            raise ValueError("Name must contain only letters")
        return v
```

### 9.2 SQL Injection Prevention

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Parameterized queries only** | ðŸ”´ CRITICAL | Jamais de f-strings avec user input |
| [x] | **ORM par dÃ©faut** | ðŸ”´ CRITICAL | SQLAlchemy, Tortoise, etc. |
| [x] | **Audit raw SQL** | ðŸ”´ CRITICAL | Review toute requÃªte raw |
| [x] | **Escape identifiers** | ðŸ”´ CRITICAL | Si dynamic column names |

```python
# âŒ JAMAIS
query = f"SELECT * FROM users WHERE email = '{email}'"

# âœ… Toujours
query = "SELECT * FROM users WHERE email = :email"
result = await db.execute(query, {"email": email})

# âœ… Avec SQLAlchemy ORM
user = await session.execute(
    select(User).where(User.email == email)
)
```

### 9.3 Path Traversal Prevention

> â„¹ï¸ **Note**: Pas de file upload dans l'application actuellement. Items Ã  implÃ©menter si feature ajoutÃ©e.

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [N/A] | **Whitelist extensions** | ðŸ”´ CRITICAL | Si file upload - pas de file upload actuellement |
| [N/A] | **Sanitize filenames** | ðŸ”´ CRITICAL | Supprimer `../`, `..\\` - pas de file upload |
| [N/A] | **UUID pour stockage** | ðŸŸ  HIGH | Renommer fichiers uploadÃ©s - pas de file upload |
| [N/A] | **VÃ©rifier path final** | ðŸ”´ CRITICAL | `os.path.realpath()` - pas de file upload |

---

## 10. Architecture - Structure projet

### 10.1 Layout recommandÃ©

```
app/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ main.py                    # FastAPI app factory
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Settings (pydantic-settings)
â”‚   â”œâ”€â”€ security.py            # JWT, hashing utilities
â”‚   â”œâ”€â”€ dependencies.py        # FastAPI dependencies
â”‚   â”œâ”€â”€ exceptions.py          # Custom exceptions
â”‚   â””â”€â”€ constants.py           # Enums, constantes
â”œâ”€â”€ middleware/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ request_id.py          # X-Request-ID
â”‚   â”œâ”€â”€ tenant.py              # X-Tenant-ID extraction
â”‚   â”œâ”€â”€ rate_limit.py          # Rate limiting
â”‚   â”œâ”€â”€ timing.py              # Response time logging
â”‚   â””â”€â”€ security_headers.py    # Security headers
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ deps.py                # Shared dependencies
â”‚   â””â”€â”€ v1/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ router.py          # Aggregated router
â”‚       â”œâ”€â”€ auth.py
â”‚       â”œâ”€â”€ users.py
â”‚       â”œâ”€â”€ sessions.py
â”‚       â”œâ”€â”€ mfa.py
â”‚       â””â”€â”€ api_keys.py
â”œâ”€â”€ services/                  # Business logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auth_service.py
â”‚   â”œâ”€â”€ user_service.py
â”‚   â”œâ”€â”€ session_service.py
â”‚   â”œâ”€â”€ mfa_service.py
â”‚   â”œâ”€â”€ token_service.py
â”‚   â””â”€â”€ audit_service.py
â”œâ”€â”€ repositories/              # Data access
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                # Base repository
â”‚   â”œâ”€â”€ user_repo.py
â”‚   â”œâ”€â”€ session_repo.py
â”‚   â”œâ”€â”€ token_repo.py
â”‚   â””â”€â”€ audit_repo.py
â”œâ”€â”€ models/                    # SQLAlchemy models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ user.py
â”‚   â”œâ”€â”€ session.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ schemas/                   # Pydantic schemas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auth.py
â”‚   â”œâ”€â”€ user.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ session.py             # DB session factory
â”‚   â””â”€â”€ migrations/            # Alembic
â””â”€â”€ tests/
    â”œâ”€â”€ conftest.py
    â”œâ”€â”€ unit/
    â”œâ”€â”€ integration/
    â””â”€â”€ e2e/
```

### 10.2 Checklist structure

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **SÃ©paration claire des couches** | ðŸ”´ CRITICAL | API â†’ Service â†’ Repository â†’ DB |
| [x] | **Pas de logique dans routers** | ðŸ”´ CRITICAL | Routers = thin, dÃ©lÃ¨guent aux services |
| [x] | **Services injectables** | ðŸŸ  HIGH | Facilite les tests |
| [x] | **Config centralisÃ©e** | ðŸ”´ CRITICAL | Un seul endroit pour settings |
| [x] | **Exceptions custom** | ðŸŸ  HIGH | Pas de HTTPException dans services |
| [x] | **Schemas sÃ©parÃ©s** | ðŸŸ  HIGH | Request â‰  Response â‰  DB model |

---

## 11. Architecture - Middleware Stack

### 11.1 Ordre des middlewares

L'ordre est **CRITIQUE**. Dernier ajoutÃ© = premier exÃ©cutÃ©.

```python
# âœ… Ordre correct (lecture de bas en haut pour l'exÃ©cution)
app = FastAPI()

# 7. CORS (doit Ãªtre premier pour preflight)
app.add_middleware(CORSMiddleware, ...)

# 6. Security Headers
app.add_middleware(SecurityHeadersMiddleware)

# 5. Rate Limiting (avant auth pour protÃ©ger)
app.add_middleware(RateLimitMiddleware, ...)

# 4. Tenant Extraction
app.add_middleware(TenantMiddleware)

# 3. Request ID (pour traÃ§abilitÃ©)
app.add_middleware(RequestIDMiddleware)

# 2. Timing (pour metrics)
app.add_middleware(TimingMiddleware)

# 1. Exception Handler (catch-all)
app.add_middleware(ExceptionMiddleware)
```

### 11.2 Checklist middlewares

| # | Middleware | PrioritÃ© | ResponsabilitÃ© |
|---|------------|----------|----------------|
| [x] | **RequestIDMiddleware** | ðŸ”´ CRITICAL | GÃ©nÃ¨re/propage X-Request-ID |
| [x] | **TenantMiddleware** | ðŸ”´ CRITICAL | X-Tenant-ID â†’ request.state |
| [x] | **RateLimitMiddleware** | ðŸ”´ CRITICAL | Anti-abus global |
| [x] | **SecurityHeadersMiddleware** | ðŸ”´ CRITICAL | HSTS, X-Frame-Options, etc. |
| [x] | **TimingMiddleware** | ðŸŸ  HIGH | Log response time |
| [x] | **ExceptionMiddleware** | ðŸ”´ CRITICAL | Catch-all, format erreurs |
| [x] | **CORSMiddleware** | ðŸ”´ CRITICAL | Si cross-origin |
| [x] | **GZipMiddleware** | ðŸŸ¡ MEDIUM | Compression responses |

```python
# âœ… Request ID middleware
import uuid
from starlette.middleware.base import BaseHTTPMiddleware

class RequestIDMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        # Get from header or generate
        request_id = request.headers.get("X-Request-ID") or str(uuid.uuid4())
        
        # Store in request state
        request.state.request_id = request_id
        
        # Add to logging context
        # structlog.contextvars.bind_contextvars(request_id=request_id)
        
        response = await call_next(request)
        
        # Echo back in response
        response.headers["X-Request-ID"] = request_id
        
        return response
```

---

## 12. Architecture - Dependency Injection

### 12.1 Dependencies standard

```python
# âœ… app/core/dependencies.py
from typing import Annotated, Optional
from fastapi import Depends, HTTPException, Request
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from sqlalchemy.ext.asyncio import AsyncSession

from app.db.session import get_async_session
from app.core.security import decode_access_token
from app.models import User
from app.repositories import UserRepository, TokenRepository

# Type aliases pour clartÃ©
security = HTTPBearer()

async def get_db() -> AsyncSession:
    async with get_async_session() as session:
        yield session

DB = Annotated[AsyncSession, Depends(get_db)]

async def get_tenant_id(request: Request) -> int:
    tenant_id = request.headers.get("X-Tenant-ID")
    if not tenant_id:
        raise HTTPException(400, "X-Tenant-ID header required")
    try:
        return int(tenant_id)
    except ValueError:
        raise HTTPException(400, "Invalid X-Tenant-ID")

TenantID = Annotated[int, Depends(get_tenant_id)]

async def get_current_user(
    credentials: Annotated[HTTPAuthorizationCredentials, Depends(security)],
    db: DB,
    tenant_id: TenantID,
) -> User:
    token = credentials.credentials
    payload = decode_access_token(token)
    
    if not payload:
        raise HTTPException(401, "Invalid token")
    
    # Type check
    if payload.get("type") != "access":
        raise HTTPException(401, "Invalid token type")
    
    # Extract and validate user_id
    try:
        user_id = int(payload["sub"])
        if user_id <= 0:
            raise ValueError()
    except (KeyError, ValueError, TypeError):
        raise HTTPException(401, "Invalid token subject")
    
    # Check blacklist
    jti = payload.get("jti")
    if jti:
        token_repo = TokenRepository(db)
        if await token_repo.is_revoked(jti):
            raise HTTPException(401, "Token revoked")
    
    # Check session if present
    session_id = payload.get("session_id")
    if session_id:
        session_repo = SessionRepository(db)
        session = await session_repo.get(session_id)
        if not session or session.revoked_at:
            raise HTTPException(401, "Session expired")
    
    # Get user
    user_repo = UserRepository(db)
    user = await user_repo.get(user_id)
    if not user:
        raise HTTPException(401, "User not found")
    
    # Cross-tenant check
    if payload.get("tenant_id") != user.tenant_id:
        raise HTTPException(401, "Tenant mismatch")
    
    # Verify request tenant matches token tenant
    if tenant_id != user.tenant_id:
        raise HTTPException(403, "Tenant access denied")
    
    return user

CurrentUser = Annotated[User, Depends(get_current_user)]

async def get_current_user_optional(
    request: Request,
    db: DB,
) -> Optional[User]:
    """For endpoints that work with or without auth"""
    auth = request.headers.get("Authorization")
    if not auth:
        return None
    try:
        credentials = HTTPAuthorizationCredentials(
            scheme="Bearer",
            credentials=auth.replace("Bearer ", "")
        )
        return await get_current_user(credentials, db, ...)
    except HTTPException:
        return None

OptionalUser = Annotated[Optional[User], Depends(get_current_user_optional)]
```

### 12.2 Checklist DI

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [ ] | **Type hints avec Annotated** | ðŸŸ  HIGH | ClartÃ© et rÃ©utilisabilitÃ© |
| [x] | **Pas de dÃ©pendance circulaire** | ðŸ”´ CRITICAL | VÃ©rifiÃ© via scripts/check_imports.py |
| [x] | **Dependencies async** | ðŸ”´ CRITICAL | Pas de sync dans async chain |
| [ ] | **Scope correct** | ðŸŸ  HIGH | Request scope par dÃ©faut |
| [ ] | **Cache par requÃªte** | ðŸŸ¡ MEDIUM | `use_cache=True` si heavy |
| [ ] | **Error messages clairs** | ðŸŸ  HIGH | Pas de 500 pour input invalide |

---

## 13. Architecture - Service Layer

### 13.1 ResponsabilitÃ©s

| Couche | ResponsabilitÃ© | Exemple |
|--------|----------------|---------|
| **Router** | HTTP handling, validation, response | Parse request, call service, return JSON |
| **Service** | Business logic, orchestration | Validate rules, coordinate repos, emit events |
| **Repository** | Data access | CRUD operations, queries |

### 13.2 Pattern Service

```python
# âœ… app/services/auth_service.py
from typing import Optional
from app.repositories import UserRepository, SessionRepository, TokenRepository
from app.schemas.auth import LoginResponse, TokenPair
from app.core.security import verify_password, create_access_token, create_refresh_token
from app.core.exceptions import InvalidCredentials, AccountLocked, MFARequired

class AuthService:
    def __init__(
        self,
        user_repo: UserRepository,
        session_repo: SessionRepository,
        token_repo: TokenRepository,
        audit_service: "AuditService",
        mfa_service: "MFAService",
    ):
        self.user_repo = user_repo
        self.session_repo = session_repo
        self.token_repo = token_repo
        self.audit = audit_service
        self.mfa = mfa_service
    
    async def login(
        self,
        email: str,
        password: str,
        ip: str,
        user_agent: str,
    ) -> LoginResponse:
        # Normalize
        email = email.lower().strip()
        
        # Get user (timing-safe)
        user = await self.user_repo.get_by_email(email)
        hash_to_check = user.password_hash if user else DUMMY_HASH
        
        password_valid = verify_password(password, hash_to_check)
        
        if not user or not password_valid:
            await self.audit.log_failed_login(email, ip)
            raise InvalidCredentials()
        
        # Check account status
        if user.locked_until and user.locked_until > datetime.utcnow():
            raise AccountLocked(until=user.locked_until)
        
        # Check MFA
        if await self.mfa.is_enabled(user.id):
            mfa_token = self.mfa.create_session_token(user.id, user.tenant_id)
            return LoginResponse(
                mfa_required=True,
                mfa_session_token=mfa_token,
            )
        
        # Create session
        session = await self.session_repo.create(
            user_id=user.id,
            tenant_id=user.tenant_id,
            ip=ip,
            user_agent=user_agent,
        )
        
        # Generate tokens
        access = create_access_token(user.id, user.tenant_id, session.id)
        refresh = create_refresh_token(session.id)
        
        # Store refresh token
        await self.token_repo.create_refresh_token(
            jti=refresh.jti,
            session_id=session.id,
            token_hash=refresh.hash,
            expires_at=refresh.expires_at,
        )
        
        # Audit
        await self.audit.log_successful_login(user.id, session.id, ip)
        
        return LoginResponse(
            access_token=access.token,
            refresh_token=refresh.token,
            token_type="bearer",
            expires_in=access.expires_in,
        )
```

### 13.3 Injection du service

```python
# âœ… Dependency pour injecter le service
from functools import lru_cache

def get_auth_service(db: DB) -> AuthService:
    return AuthService(
        user_repo=UserRepository(db),
        session_repo=SessionRepository(db),
        token_repo=TokenRepository(db),
        audit_service=AuditService(db),
        mfa_service=MFAService(db),
    )

AuthServiceDep = Annotated[AuthService, Depends(get_auth_service)]

# âœ… Router utilise le service
@router.post("/login", response_model=LoginResponse)
async def login(
    request: Request,
    data: LoginRequest,
    auth_service: AuthServiceDep,
):
    return await auth_service.login(
        email=data.email,
        password=data.password,
        ip=request.client.host,
        user_agent=request.headers.get("User-Agent", ""),
    )
```

### 13.4 Checklist Service Layer

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Pas de HTTPException dans services** | ðŸ”´ CRITICAL | Lever des exceptions custom |
| [x] | **Pas d'accÃ¨s Request dans services** | ðŸ”´ CRITICAL | Passer les valeurs en params |
| [x] | **Transactions explicites** | ðŸ”´ CRITICAL | Service contrÃ´le les boundaries |
| [x] | **Services testables** | ðŸŸ  HIGH | Injection des dÃ©pendances |
| [x] | **Single responsibility** | ðŸŸ  HIGH | Un service = un domaine |
| [x] | **Audit dans le service** | ðŸŸ  HIGH | Pas dans le router |

---

## 14. Architecture - Repository Pattern

### 14.1 Base Repository

```python
# âœ… app/repositories/base.py
from typing import TypeVar, Generic, Optional, List, Type
from sqlalchemy import select, update, delete
from sqlalchemy.ext.asyncio import AsyncSession
from app.models.base import Base

ModelType = TypeVar("ModelType", bound=Base)

class BaseRepository(Generic[ModelType]):
    def __init__(self, session: AsyncSession, model: Type[ModelType]):
        self.session = session
        self.model = model
    
    async def get(self, id: int) -> Optional[ModelType]:
        result = await self.session.execute(
            select(self.model).where(self.model.id == id)
        )
        return result.scalar_one_or_none()
    
    async def get_by_ids(self, ids: List[int]) -> List[ModelType]:
        result = await self.session.execute(
            select(self.model).where(self.model.id.in_(ids))
        )
        return list(result.scalars().all())
    
    async def create(self, **kwargs) -> ModelType:
        instance = self.model(**kwargs)
        self.session.add(instance)
        await self.session.flush()
        return instance
    
    async def update(self, id: int, **kwargs) -> Optional[ModelType]:
        await self.session.execute(
            update(self.model)
            .where(self.model.id == id)
            .values(**kwargs)
        )
        return await self.get(id)
    
    async def delete(self, id: int) -> bool:
        result = await self.session.execute(
            delete(self.model).where(self.model.id == id)
        )
        return result.rowcount > 0
```

### 14.2 Repository spÃ©cialisÃ©

```python
# âœ… app/repositories/user_repo.py
from typing import Optional
from sqlalchemy import select
from app.models import User
from app.repositories.base import BaseRepository

class UserRepository(BaseRepository[User]):
    def __init__(self, session: AsyncSession):
        super().__init__(session, User)
    
    async def get_by_email(self, email: str) -> Optional[User]:
        result = await self.session.execute(
            select(User).where(User.email == email.lower())
        )
        return result.scalar_one_or_none()
    
    async def get_by_tenant(
        self,
        tenant_id: int,
        limit: int = 100,
        offset: int = 0,
    ) -> List[User]:
        result = await self.session.execute(
            select(User)
            .where(User.tenant_id == tenant_id)
            .limit(limit)
            .offset(offset)
        )
        return list(result.scalars().all())
    
    async def email_exists(self, email: str, tenant_id: int) -> bool:
        result = await self.session.execute(
            select(User.id)
            .where(User.email == email.lower())
            .where(User.tenant_id == tenant_id)
            .limit(1)
        )
        return result.scalar_one_or_none() is not None
```

### 14.3 Checklist Repository

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Pas de logique mÃ©tier** | ðŸ”´ CRITICAL | Que du CRUD et queries |
| [x] | **Pas de commit** | ðŸ”´ CRITICAL | Service contrÃ´le la transaction |
| [x] | **Tenant isolation** | ðŸ”´ CRITICAL | Toujours filtrer par tenant_id |
| [x] | **Return models, pas dicts** | ðŸŸ  HIGH | Type safety |
| [x] | **Pagination par dÃ©faut** | ðŸŸ  HIGH | Ã‰viter les SELECT sans LIMIT |
| [x] | **Async everywhere** | ðŸ”´ CRITICAL | Pas de sync DB calls |

---

## 15. Architecture - Exception Handling

### 15.1 Custom Exceptions

```python
# âœ… app/core/exceptions.py
from typing import Optional, Dict, Any

class AppException(Exception):
    """Base exception for application"""
    status_code: int = 500
    error_code: str = "INTERNAL_ERROR"
    message: str = "An unexpected error occurred"
    
    def __init__(
        self,
        message: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None,
    ):
        self.message = message or self.message
        self.details = details or {}
        super().__init__(self.message)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "error": self.error_code,
            "message": self.message,
            "details": self.details,
        }

# Auth exceptions
class InvalidCredentials(AppException):
    status_code = 401
    error_code = "INVALID_CREDENTIALS"
    message = "Invalid email or password"

class TokenExpired(AppException):
    status_code = 401
    error_code = "TOKEN_EXPIRED"
    message = "Token has expired"

class TokenRevoked(AppException):
    status_code = 401
    error_code = "TOKEN_REVOKED"
    message = "Token has been revoked"

class SessionExpired(AppException):
    status_code = 401
    error_code = "SESSION_EXPIRED"
    message = "Session has expired"

class AccountLocked(AppException):
    status_code = 403
    error_code = "ACCOUNT_LOCKED"
    message = "Account is temporarily locked"
    
    def __init__(self, until: datetime):
        super().__init__(details={"locked_until": until.isoformat()})

class MFARequired(AppException):
    status_code = 403
    error_code = "MFA_REQUIRED"
    message = "Multi-factor authentication required"

class MFAInvalid(AppException):
    status_code = 401
    error_code = "MFA_INVALID"
    message = "Invalid MFA code"

# Permission exceptions
class PermissionDenied(AppException):
    status_code = 403
    error_code = "PERMISSION_DENIED"
    message = "You don't have permission to perform this action"

class TenantMismatch(AppException):
    status_code = 403
    error_code = "TENANT_MISMATCH"
    message = "Tenant access denied"

# Resource exceptions
class NotFound(AppException):
    status_code = 404
    error_code = "NOT_FOUND"
    message = "Resource not found"

class AlreadyExists(AppException):
    status_code = 409
    error_code = "ALREADY_EXISTS"
    message = "Resource already exists"

# Validation exceptions
class ValidationError(AppException):
    status_code = 422
    error_code = "VALIDATION_ERROR"
    message = "Validation failed"

# Rate limiting
class RateLimitExceeded(AppException):
    status_code = 429
    error_code = "RATE_LIMIT_EXCEEDED"
    message = "Too many requests"
```

### 15.2 Global Exception Handler

```python
# âœ… app/core/exception_handlers.py
from fastapi import Request, FastAPI
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from app.core.exceptions import AppException
import structlog

logger = structlog.get_logger()

def setup_exception_handlers(app: FastAPI):
    
    @app.exception_handler(AppException)
    async def app_exception_handler(request: Request, exc: AppException):
        logger.warning(
            "Application error",
            error_code=exc.error_code,
            message=exc.message,
            path=request.url.path,
            request_id=getattr(request.state, "request_id", None),
        )
        return JSONResponse(
            status_code=exc.status_code,
            content=exc.to_dict(),
        )
    
    @app.exception_handler(RequestValidationError)
    async def validation_exception_handler(request: Request, exc: RequestValidationError):
        errors = []
        for error in exc.errors():
            errors.append({
                "field": ".".join(str(loc) for loc in error["loc"]),
                "message": error["msg"],
                "type": error["type"],
            })
        
        return JSONResponse(
            status_code=422,
            content={
                "error": "VALIDATION_ERROR",
                "message": "Request validation failed",
                "details": {"errors": errors},
            },
        )
    
    @app.exception_handler(Exception)
    async def unhandled_exception_handler(request: Request, exc: Exception):
        request_id = getattr(request.state, "request_id", "unknown")
        
        logger.exception(
            "Unhandled exception",
            request_id=request_id,
            path=request.url.path,
            method=request.method,
        )
        
        return JSONResponse(
            status_code=500,
            content={
                "error": "INTERNAL_ERROR",
                "message": "An unexpected error occurred",
                "details": {"request_id": request_id},
            },
        )
```

### 15.3 Checklist Exceptions

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Exceptions custom typÃ©es** | ðŸ”´ CRITICAL | Pas de `raise Exception("...")` |
| [x] | **Error codes constants** | ðŸ”´ CRITICAL | Pour parsing cÃ´tÃ© client |
| [x] | **Messages user-friendly** | ðŸŸ  HIGH | Pas de stack traces en prod |
| [x] | **Request ID dans les 500** | ðŸ”´ CRITICAL | Pour debugging |
| [x] | **Log toutes les erreurs** | ðŸ”´ CRITICAL | Structured logging |
| [x] | **Ne pas leak d'infos sensibles** | ðŸ”´ CRITICAL | Pas de SQL, paths, etc. |
| [x] | **Validation errors dÃ©taillÃ©es** | ðŸŸ  HIGH | Field-level feedback |

---

## 16. Multi-tenant

### 16.1 Isolation

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **tenant_id sur toutes les tables** | ðŸ”´ CRITICAL | Sauf tables globales (permissions) |
| [x] | **Validation header X-Tenant-ID** | ðŸ”´ CRITICAL | Middleware obligatoire |
| [x] | **RLS PostgreSQL** | ðŸ”´ CRITICAL | Defense in depth |
| [x] | **Cross-tenant check dans get_current_user** | ðŸ”´ CRITICAL | Token.tenant == User.tenant |
| [x] | **Tenant dans tous les logs** | ðŸŸ  HIGH | Pour audit |
| [x] | **Indexes avec tenant_id** | ðŸŸ  HIGH | Perf queries |

### 16.2 Row Level Security

```sql
-- âœ… RLS setup
ALTER TABLE users ENABLE ROW LEVEL SECURITY;
ALTER TABLE sessions ENABLE ROW LEVEL SECURITY;
ALTER TABLE api_keys ENABLE ROW LEVEL SECURITY;
-- ... toutes les tables tenant-scoped

-- Policy de base
CREATE POLICY tenant_isolation ON users
    USING (tenant_id = current_setting('app.current_tenant_id')::bigint);

-- Pour les admins systÃ¨me (bypass)
CREATE POLICY admin_bypass ON users
    USING (current_setting('app.is_system_admin', true)::boolean = true);
```

```python
# âœ… Set tenant context for RLS
async def set_tenant_context(session: AsyncSession, tenant_id: int):
    await session.execute(
        text(f"SET LOCAL app.current_tenant_id = '{tenant_id}'")
    )
```

### 16.3 Tenant Middleware

```python
# âœ… app/middleware/tenant.py
from starlette.middleware.base import BaseHTTPMiddleware
from fastapi import HTTPException

class TenantMiddleware(BaseHTTPMiddleware):
    # Endpoints qui ne requiÃ¨rent pas de tenant
    TENANT_EXEMPT = {
        "/health",
        "/ready",
        "/docs",
        "/openapi.json",
    }
    
    async def dispatch(self, request, call_next):
        if request.url.path in self.TENANT_EXEMPT:
            return await call_next(request)
        
        tenant_header = request.headers.get("X-Tenant-ID")
        
        if not tenant_header:
            return JSONResponse(
                status_code=400,
                content={"error": "MISSING_TENANT", "message": "X-Tenant-ID header required"}
            )
        
        try:
            tenant_id = int(tenant_header)
            if tenant_id <= 0:
                raise ValueError()
        except ValueError:
            return JSONResponse(
                status_code=400,
                content={"error": "INVALID_TENANT", "message": "Invalid X-Tenant-ID"}
            )
        
        request.state.tenant_id = tenant_id
        
        return await call_next(request)
```

---

## 17. Base de donnÃ©es - Schema

### 17.1 Tables obligatoires

| # | Table | PrioritÃ© | RÃ´le |
|---|-------|----------|------|
| [x] | **tenants** | ðŸ”´ CRITICAL | Organisations |
| [x] | **users** | ðŸ”´ CRITICAL | Utilisateurs |
| [x] | **sessions** | ðŸ”´ CRITICAL | Sessions actives |
| [x] | **refresh_tokens** | ðŸ”´ CRITICAL | Tokens de refresh |
| [x] | **revoked_tokens** | ðŸ”´ CRITICAL | Blacklist JWT |
| [x] | **login_attempts** | ðŸ”´ CRITICAL | Anti-bruteforce |
| [x] | **audit_log** | ðŸ”´ CRITICAL | TraÃ§abilitÃ© |
| [x] | **mfa_secrets** | ðŸŸ  HIGH | TOTP secrets |
| [x] | **mfa_recovery_codes** | ðŸŸ  HIGH | Recovery codes |
| [x] | **verification_tokens** | ðŸŸ  HIGH | Email verify, password reset |
| [x] | **api_keys** | ðŸŸ  HIGH | M2M auth |
| [x] | **roles** | ðŸŸ  HIGH | RBAC |
| [x] | **permissions** | ðŸŸ  HIGH | RBAC |
| [x] | **user_roles** | ðŸŸ  HIGH | RBAC |

### 17.2 Conventions

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **snake_case pour colonnes** | ðŸŸ  HIGH | Consistance |
| [x] | **Pluriel pour tables** | ðŸŸ¡ MEDIUM | users, sessions, tokens |
| [x] | **id BIGSERIAL ou UUID** | ðŸŸ  HIGH | Selon le cas d'usage |
| [x] | **created_at sur toutes les tables** | ðŸ”´ CRITICAL | Audit |
| [x] | **updated_at oÃ¹ pertinent** | ðŸŸ  HIGH | Tracking modifications |
| [x] | **Soft delete avec deleted_at** | ðŸŸ  HIGH | Ou revoked_at selon contexte |
| [x] | **TIMESTAMPTZ pas TIMESTAMP** | ðŸ”´ CRITICAL | Timezone-aware |
| [x] | **NOT NULL par dÃ©faut** | ðŸŸ  HIGH | Expliciter les optionnels |
| [x] | **DEFAULT values** | ðŸŸ  HIGH | NOW(), false, etc. |

### 17.3 Contraintes

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **PK sur toutes les tables** | ðŸ”´ CRITICAL | Ã‰vident mais Ã  vÃ©rifier |
| [x] | **FK avec ON DELETE** | ðŸ”´ CRITICAL | CASCADE ou RESTRICT explicite |
| [x] | **UNIQUE constraints** | ðŸ”´ CRITICAL | (tenant_id, email), etc. |
| [x] | **CHECK constraints** | ðŸŸ  HIGH | Valider les enums en DB |
| [x] | **Indexes explicites** | ðŸ”´ CRITICAL | Pas juste implicites des FK |

---

## 18. Base de donnÃ©es - Performance

### 18.1 Index Strategy

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Index sur FK** | ðŸ”´ CRITICAL | PostgreSQL ne les crÃ©e pas auto |
| [x] | **Index composites** | ðŸŸ  HIGH | (tenant_id, created_at DESC) |
| [x] | **Index partiels** | ðŸŸ  HIGH | WHERE revoked_at IS NULL |
| [x] | **EXPLAIN ANALYZE** | ðŸ”´ CRITICAL | `app/core/query_profiler.py` - explain_analyze() + N+1 detection |
| [ ] | **Pas d'index inutilisÃ©s** | ðŸŸ¡ MEDIUM | Cleanup rÃ©gulier |
| [ ] | **Index covering** | ðŸŸ¡ MEDIUM | INCLUDE pour Ã©viter heap fetch |

```sql
-- âœ… Exemples d'index optimisÃ©s

-- Sessions actives par user (query frÃ©quente)
CREATE INDEX sessions_user_active_idx 
    ON sessions (user_id, created_at DESC)
    WHERE revoked_at IS NULL;

-- Lookup refresh token par hash
CREATE INDEX refresh_tokens_hash_idx 
    ON refresh_tokens (token_hash)
    WHERE used_at IS NULL;

-- Audit log par tenant + date (reporting)
CREATE INDEX audit_log_tenant_time_idx 
    ON audit_log (tenant_id, created_at DESC);

-- Login attempts pour rate limiting
CREATE INDEX login_attempts_identifier_recent_idx 
    ON login_attempts (identifier, attempted_at DESC);

-- API keys lookup
CREATE INDEX api_keys_hash_active_idx 
    ON api_keys (key_hash)
    WHERE revoked_at IS NULL AND (expires_at IS NULL OR expires_at > NOW());
```

### 18.2 Connection Pooling

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Pool size configurÃ©** | ðŸ”´ CRITICAL | Selon workers * connections |
| [x] | **Max overflow** | ðŸŸ  HIGH | Buffer pour pics |
| [x] | **Connection timeout** | ðŸŸ  HIGH | Fail fast |
| [x] | **Recycle connections** | ðŸŸ  HIGH | Ã‰viter stale connections |
| [N/A] | **PgBouncer en prod** | ðŸŸ  HIGH | Infrastructure-specific - Ã  configurer selon environnement |

```python
# âœ… SQLAlchemy async pool config
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

engine = create_async_engine(
    settings.DATABASE_URL,
    pool_size=5,           # Base connections
    max_overflow=10,       # Extra connections on demand
    pool_timeout=30,       # Wait for available connection
    pool_recycle=1800,     # Recycle after 30 minutes
    pool_pre_ping=True,    # Verify connection before use
    echo=settings.DEBUG,   # SQL logging
)

async_session = sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
)
```

### 18.3 Query Optimization

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Pagination obligatoire** | ðŸ”´ CRITICAL | PaginatedResult dans BaseRepository |
| [ ] | **Ã‰viter SELECT *** | ðŸŸ  HIGH | SÃ©lectionner les colonnes nÃ©cessaires |
| [x] | **N+1 detection** | ðŸ”´ CRITICAL | QueryProfiler avec dÃ©tection N+1 |
| [ ] | **Batch operations** | ðŸŸ  HIGH | Bulk insert/update |
| [ ] | **Read replicas** | ðŸŸ¡ MEDIUM | Pour requÃªtes heavy read |

---

## 19. Base de donnÃ©es - Maintenance

### 19.1 Cleanup automatique

| # | Table | RÃ©tention | FrÃ©quence |
|---|-------|-----------|-----------|
| [x] | **revoked_tokens** | expires_at passÃ© | Daily |
| [x] | **refresh_tokens** | expires_at passÃ© | Daily |
| [x] | **login_attempts** | 30 jours | Daily |
| [ ] | **audit_log** | 12 mois (ou selon compliance) | Weekly |
| [x] | **password_reset_tokens** | expires_at passÃ© | Daily |
| [x] | **sessions** | revoked > 90 jours | Weekly |

```sql
-- âœ… Cleanup script (Ã  scheduler)

-- Revoked tokens expirÃ©s
DELETE FROM revoked_tokens WHERE expires_at < NOW();

-- Refresh tokens expirÃ©s
DELETE FROM refresh_tokens WHERE expires_at < NOW();

-- Login attempts vieux
DELETE FROM login_attempts WHERE attempted_at < NOW() - INTERVAL '30 days';

-- Sessions rÃ©voquÃ©es anciennes
DELETE FROM sessions WHERE revoked_at < NOW() - INTERVAL '90 days';

-- Verification tokens expirÃ©s
DELETE FROM verification_tokens WHERE expires_at < NOW();
```

### 19.2 Vacuum & Analyze

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **autovacuum activÃ©** | ðŸ”´ CRITICAL | Par dÃ©faut sur PostgreSQL |
| [x] | **Tune autovacuum** | ðŸŸ  HIGH | db/sql/01_autovacuum.sql |
| [ ] | **VACUUM ANALYZE manuel** | ðŸŸ  HIGH | AprÃ¨s gros DELETE/UPDATE |
| [ ] | **pg_repack** | ðŸŸ¡ MEDIUM | Pour tables bloated |

### 19.3 Backups

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **pg_dump quotidien** | ðŸ”´ CRITICAL | Backup logique |
| [x] | **WAL archiving** | ðŸ”´ CRITICAL | Point-in-time recovery |
| [x] | **Test restore rÃ©gulier** | ðŸ”´ CRITICAL | Un backup non testÃ© n'existe pas |
| [x] | **Offsite storage** | ðŸ”´ CRITICAL | S3, GCS, autre rÃ©gion |
| [x] | **Encryption at rest** | ðŸŸ  HIGH | Backups chiffrÃ©s |
| [x] | **Retention policy** | ðŸŸ  HIGH | 7 daily, 4 weekly, 12 monthly |

---

## 20. ObservabilitÃ© - Logging

### 20.1 Structured Logging

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Format JSON** | ðŸ”´ CRITICAL | Parsable par outils (ELK, Datadog) |
| [x] | **structlog ou python-json-logger** | ðŸŸ  HIGH | Librairie Ã©prouvÃ©e |
| [x] | **Levels cohÃ©rents** | ðŸŸ  HIGH | DEBUG, INFO, WARNING, ERROR, CRITICAL |
| [x] | **Request ID dans tous les logs** | ðŸ”´ CRITICAL | CorrÃ©lation |
| [x] | **Tenant ID dans tous les logs** | ðŸ”´ CRITICAL | Multi-tenant debug |
| [x] | **User ID (quand auth)** | ðŸŸ  HIGH | `logging.py` - ContextVar user_id dans logs |
| [x] | **Timestamps ISO 8601** | ðŸŸ  HIGH | Tous les modÃ¨les utilisent `.isoformat()` |

```python
# âœ… Configuration structlog
import structlog
from structlog.contextvars import merge_contextvars

structlog.configure(
    processors=[
        merge_contextvars,
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer(),
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# Usage
logger.info(
    "User logged in",
    user_id=user.id,
    tenant_id=user.tenant_id,
    ip=request.client.host,
)
```

### 20.2 Que logger

| Event | Level | Champs obligatoires |
|-------|-------|---------------------|
| Request start | DEBUG | method, path, request_id |
| Request end | INFO | method, path, status, duration_ms, request_id |
| Auth success | INFO | user_id, tenant_id, ip |
| Auth failure | WARNING | identifier, ip, reason |
| Permission denied | WARNING | user_id, action, resource |
| Validation error | INFO | path, errors |
| Business error | WARNING | error_code, message |
| System error | ERROR | exception, stack_trace, request_id |
| Rate limit hit | WARNING | ip, endpoint, limit |
| MFA events | INFO | user_id, event_type |
| Session events | INFO | session_id, event_type |

### 20.3 Ce qu'il ne faut PAS logger

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Pas de mots de passe** | ðŸ”´ CRITICAL | Jamais, mÃªme en debug |
| [x] | **Pas de tokens complets** | ðŸ”´ CRITICAL | Max 8 premiers chars |
| [x] | **Pas de secrets** | ðŸ”´ CRITICAL | API keys, encryption keys |
| [x] | **Pas de PII excessive** | ðŸŸ  HIGH | Email OK, SSN jamais |
| [x] | **Pas de card numbers** | ðŸ”´ CRITICAL | PCI compliance |
| [x] | **Pas de request body sensible** | ðŸŸ  HIGH | Filter login payloads |

```python
# âœ… Sanitize sensitive data
SENSITIVE_FIELDS = {"password", "token", "secret", "api_key", "authorization"}

def sanitize_dict(data: dict) -> dict:
    result = {}
    for key, value in data.items():
        if any(sensitive in key.lower() for sensitive in SENSITIVE_FIELDS):
            result[key] = "[REDACTED]"
        elif isinstance(value, dict):
            result[key] = sanitize_dict(value)
        else:
            result[key] = value
    return result
```

---

## 21. ObservabilitÃ© - Metrics

### 21.1 Metrics essentielles

| # | Metric | Type | Labels |
|---|--------|------|--------|
| [x] | **http_requests_total** | Counter | method, path, status |
| [x] | **http_request_duration_seconds** | Histogram | method, path |
| [x] | **auth_login_total** | Counter | status (success/failure), tenant_id |
| [x] | **auth_mfa_verify_total** | Counter | status, tenant_id |
| [x] | **active_sessions** | Gauge | tenant_id |
| [x] | **rate_limit_hits_total** | Counter | endpoint, tenant_id |
| [x] | **db_query_duration_seconds** | Histogram | query_type |
| [ ] | **db_pool_connections** | Gauge | status (active/idle) |

### 21.2 Implementation Prometheus

```python
# âœ… Prometheus metrics
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from starlette.responses import Response

# Metrics
REQUEST_COUNT = Counter(
    "http_requests_total",
    "Total HTTP requests",
    ["method", "path", "status"]
)

REQUEST_LATENCY = Histogram(
    "http_request_duration_seconds",
    "HTTP request latency",
    ["method", "path"],
    buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
)

LOGIN_ATTEMPTS = Counter(
    "auth_login_total",
    "Login attempts",
    ["status", "tenant_id"]
)

ACTIVE_SESSIONS = Gauge(
    "active_sessions",
    "Currently active sessions",
    ["tenant_id"]
)

# Endpoint
@app.get("/metrics")
async def metrics():
    return Response(
        generate_latest(),
        media_type="text/plain"
    )
```

### 21.3 Checklist Metrics

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **RED metrics** | ðŸ”´ CRITICAL | Rate, Errors, Duration |
| [x] | **USE metrics** | ðŸŸ  HIGH | Utilization, Saturation, Errors |
| [x] | **Business metrics** | ðŸŸ  HIGH | Logins, signups, etc. |
| [x] | **Cardinality contrÃ´lÃ©e** | ðŸ”´ CRITICAL | Pas de user_id dans labels |
| [N/A] | **Dashboards Grafana** | ðŸŸ  HIGH | Infrastructure/Observability - Ã  configurer sÃ©parÃ©ment |
| [x] | **Alerting rules** | ðŸ”´ CRITICAL | Prometheus Alertmanager |

---

## 22. ObservabilitÃ© - Tracing

### 22.1 Distributed Tracing

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [N/A] | **OpenTelemetry SDK** | ðŸŸ  HIGH | Infrastructure/Observability - Ã  intÃ©grer selon besoins |
| [x] | **Trace ID propagation** | ðŸ”´ CRITICAL | X-Request-ID + logging context |
| [ ] | **Span per DB query** | ðŸŸ  HIGH | Identifier slow queries |
| [ ] | **Span per HTTP call** | ðŸŸ  HIGH | External services |
| [ ] | **Sampling en prod** | ðŸŸ  HIGH | 1% ou head-based |
| [ ] | **Jaeger ou Zipkin** | ðŸŸ¡ MEDIUM | Backend de traces |

```python
# âœ… OpenTelemetry setup
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor

# Setup
provider = TracerProvider()
processor = BatchSpanProcessor(OTLPSpanExporter(endpoint="http://otel-collector:4317"))
provider.add_span_processor(processor)
trace.set_tracer_provider(provider)

# Auto-instrument
FastAPIInstrumentor.instrument_app(app)
SQLAlchemyInstrumentor().instrument(engine=engine)

# Manual span
tracer = trace.get_tracer(__name__)

async def some_complex_operation():
    with tracer.start_as_current_span("complex_operation") as span:
        span.set_attribute("user_id", user_id)
        # ... operation
```

---

## 23. Performance

### 23.1 Async Best Practices

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Async DB driver** | ðŸ”´ CRITICAL | asyncpg pour PostgreSQL |
| [x] | **Async HTTP client** | ðŸ”´ CRITICAL | httpx ou aiohttp |
| [x] | **Pas de sync dans async** | ðŸ”´ CRITICAL | Bloque l'event loop |
| [ ] | **asyncio.gather pour parallel** | ðŸŸ  HIGH | Concurrent calls |
| [ ] | **run_in_executor pour CPU-bound** | ðŸŸ  HIGH | Offload blocking |
| [x] | **Timeouts sur external calls** | ðŸ”´ CRITICAL | Pas d'attente infinie |

```python
# âŒ Mauvais - bloque l'event loop
import requests
response = requests.get("https://api.example.com")

# âœ… Bon
import httpx
async with httpx.AsyncClient(timeout=10.0) as client:
    response = await client.get("https://api.example.com")

# âœ… Parallel calls
results = await asyncio.gather(
    service_a.call(),
    service_b.call(),
    service_c.call(),
    return_exceptions=True,
)
```

### 23.2 Caching

> â„¹ï¸ **Note**: Pas de cache applicatif implÃ©mentÃ© actuellement. Redis utilisÃ© uniquement pour rate limiting.

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [N/A] | **Redis pour cache partagÃ©** | ðŸŸ  HIGH | Multi-instance - pas de cache applicatif actuellement |
| [N/A] | **TTL appropriÃ©s** | ðŸŸ  HIGH | Selon fraÃ®cheur requise - pas de cache |
| [N/A] | **Cache invalidation strategy** | ðŸ”´ CRITICAL | Ã€ implÃ©menter si cache ajoutÃ© |
| [ ] | **Cache per-request** | ðŸŸ  HIGH | get_current_user |
| [ ] | **Response caching (CDN)** | ðŸŸ¡ MEDIUM | Pour static content |
| [ ] | **ETag / If-None-Match** | ðŸŸ¡ MEDIUM | Client-side caching |

```python
# âœ… Cache decorator avec Redis
from functools import wraps
import json
import hashlib

def cached(ttl: int = 60, prefix: str = "cache"):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # Build cache key
            key_data = f"{func.__name__}:{args}:{sorted(kwargs.items())}"
            cache_key = f"{prefix}:{hashlib.md5(key_data.encode()).hexdigest()}"
            
            # Try cache
            cached = await redis.get(cache_key)
            if cached:
                return json.loads(cached)
            
            # Execute
            result = await func(*args, **kwargs)
            
            # Store
            await redis.setex(cache_key, ttl, json.dumps(result))
            
            return result
        return wrapper
    return decorator

@cached(ttl=300, prefix="user")
async def get_user_permissions(user_id: int) -> list:
    # Heavy query
    ...
```

### 23.3 Autres optimisations

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Compression gzip** | ðŸŸ  HIGH | GZipMiddleware (min_size=1000) |
| [ ] | **Response streaming** | ðŸŸ¡ MEDIUM | Pour large responses |
| [ ] | **Lazy loading** | ðŸŸ  HIGH | Ã‰viter eager loading inutile |
| [ ] | **Connection reuse** | ðŸŸ  HIGH | Keep-alive HTTP |
| [ ] | **Batch endpoints** | ðŸŸ¡ MEDIUM | RÃ©duire round-trips |
| [ ] | **Pagination cursor-based** | ðŸŸ  HIGH | Plus efficace que offset |

---

## 24. Tests

### 24.1 Test Pyramid

| Niveau | Proportion | Focus |
|--------|------------|-------|
| **Unit tests** | 70% | Services, utils, business logic |
| **Integration tests** | 20% | Repositories + DB, external services |
| **E2E tests** | 10% | Full API flows |

### 24.2 Checklist Tests

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **pytest-asyncio** | ðŸ”´ CRITICAL | Pour async tests |
| [x] | **Fixtures rÃ©utilisables** | ðŸŸ  HIGH | conftest.py |
| [x] | **DB isolation** | ðŸ”´ CRITICAL | Transaction rollback ou test DB |
| [x] | **Mocks pour external** | ðŸŸ  HIGH | Ne pas appeler vrais services |
| [ ] | **Factory pattern** | ðŸŸ  HIGH | factory_boy pour data |
| [ ] | **Coverage > 80%** | ðŸŸ  HIGH | Avec exclusions raisonnables |
| [x] | **Tests security-specific** | ðŸ”´ CRITICAL | Voir ci-dessous |

### 24.3 Tests de sÃ©curitÃ© obligatoires

| # | Test | Description |
|---|------|-------------|
| [x] | **Token expiration** | Rejeter tokens expirÃ©s |
| [x] | **Token type mismatch** | Refresh token pas acceptÃ© comme access |
| [x] | **Revoked token** | Blacklist respectÃ©e |
| [x] | **Session revoked** | Token valide mais session rÃ©voquÃ©e |
| [x] | **Cross-tenant access** | User tenant A ne peut pas accÃ©der tenant B |
| [x] | **Rate limiting** | 429 aprÃ¨s N requests |
| [x] | **Bruteforce protection** | Lock aprÃ¨s N Ã©checs |
| [x] | **Invalid JWT signature** | Rejeter tokens modifiÃ©s |
| [x] | **SQL injection** | Parameterized queries |
| [x] | **MFA replay** | Code dÃ©jÃ  utilisÃ© rejetÃ© |
| [x] | **Password validation** | RÃ¨gles respectÃ©es |

```python
# âœ… Exemple tests sÃ©curitÃ©
import pytest
from httpx import AsyncClient
from app.core.security import create_access_token

@pytest.mark.asyncio
async def test_expired_token_rejected(client: AsyncClient):
    token = create_access_token(
        user_id=1,
        tenant_id=1,
        expires_delta=timedelta(seconds=-1)  # Already expired
    )
    
    response = await client.get(
        "/api/v1/users/me",
        headers={"Authorization": f"Bearer {token}", "X-Tenant-ID": "1"}
    )
    
    assert response.status_code == 401
    assert response.json()["error"] == "TOKEN_EXPIRED"

@pytest.mark.asyncio
async def test_refresh_token_not_valid_as_access(client: AsyncClient):
    refresh_token = create_refresh_token(session_id=uuid4())
    
    response = await client.get(
        "/api/v1/users/me",
        headers={"Authorization": f"Bearer {refresh_token.token}", "X-Tenant-ID": "1"}
    )
    
    assert response.status_code == 401

@pytest.mark.asyncio
async def test_cross_tenant_access_denied(client: AsyncClient, user_tenant_1, token_tenant_2):
    # User belongs to tenant 1, token claims tenant 2
    response = await client.get(
        "/api/v1/users/me",
        headers={
            "Authorization": f"Bearer {token_tenant_2}",
            "X-Tenant-ID": "1"  # Mismatch!
        }
    )
    
    assert response.status_code in [401, 403]

@pytest.mark.asyncio
async def test_rate_limit_enforced(client: AsyncClient):
    # Exceed rate limit
    for i in range(10):
        await client.post("/api/v1/auth/login", json={"email": "test@example.com", "password": "wrong"})
    
    response = await client.post("/api/v1/auth/login", json={"email": "test@example.com", "password": "wrong"})
    
    assert response.status_code == 429
```

---

## 25. CI/CD

### 25.1 Pipeline stages

| # | Stage | PrioritÃ© | Checks |
|---|-------|----------|--------|
| [x] | **Lint** | ðŸ”´ CRITICAL | ruff, black, isort |
| [ ] | **Type check** | ðŸŸ  HIGH | mypy --strict |
| [x] | **Unit tests** | ðŸ”´ CRITICAL | pytest -m unit |
| [x] | **Integration tests** | ðŸ”´ CRITICAL | pytest -m integration (avec DB) |
| [x] | **Security scan** | ðŸ”´ CRITICAL | bandit, safety |
| [x] | **Dependency audit** | ðŸŸ  HIGH | pip-audit |
| [x] | **Build image** | ðŸ”´ CRITICAL | Docker build |
| [x] | **Image scan** | ðŸŸ  HIGH | Trivy dans `.github/workflows/security.yml` |
| [x] | **Migration test** | ðŸ”´ CRITICAL | alembic upgrade + downgrade |
| [ ] | **Deploy staging** | ðŸŸ  HIGH | Auto-deploy - infrastructure-specific |
| [ ] | **E2E tests** | ðŸŸ  HIGH | Sur staging |
| [ ] | **Deploy prod** | ðŸ”´ CRITICAL | Manuel ou auto - infrastructure-specific |

### 25.2 Pre-commit hooks

```yaml
# âœ… .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.6
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
      - id: detect-private-key

  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.6
    hooks:
      - id: bandit
        args: ["-c", "pyproject.toml"]
        additional_dependencies: ["bandit[toml]"]
```

### 25.3 GitHub Actions example

```yaml
# âœ… .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - run: pip install ruff
      - run: ruff check .
      - run: ruff format --check .

  type-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - run: pip install -e ".[dev]"
      - run: mypy app --strict

  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - run: pip install -e ".[dev]"
      - run: pytest --cov=app --cov-report=xml
      - uses: codecov/codecov-action@v3

  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - run: pip install bandit safety pip-audit
      - run: bandit -r app
      - run: safety check
      - run: pip-audit

  migration:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test
        ports:
          - 5432:5432
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - run: pip install -e ".[dev]"
      - run: alembic upgrade head
      - run: alembic downgrade base
      - run: alembic upgrade head
```

---

## 26. Documentation

### 26.1 API Documentation

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **OpenAPI spec auto** | ðŸ”´ CRITICAL | FastAPI le fait (/openapi.json, /docs) |
| [ ] | **Descriptions sur tous les endpoints** | ðŸŸ  HIGH | docstrings |
| [ ] | **Examples dans schemas** | ðŸŸ  HIGH | `schema_extra` |
| [ ] | **Error responses documentÃ©es** | ðŸŸ  HIGH | `responses={}` |
| [ ] | **Auth requirements clairs** | ðŸŸ  HIGH | Security schemes |
| [ ] | **Changelog / versioning** | ðŸŸ  HIGH | /v1, /v2 |

```python
# âœ… Well-documented endpoint
from fastapi import APIRouter, HTTPException

router = APIRouter()

@router.post(
    "/auth/login",
    response_model=LoginResponse,
    summary="Authenticate user",
    description="""
    Authenticate a user with email and password.
    
    Returns JWT tokens for API access.
    If MFA is enabled, returns a temporary MFA session token instead.
    """,
    responses={
        200: {"description": "Login successful or MFA required"},
        401: {"description": "Invalid credentials"},
        403: {"description": "Account locked"},
        429: {"description": "Too many attempts"},
    },
)
async def login(
    request: Request,
    data: LoginRequest,
    auth_service: AuthServiceDep,
):
    """Authenticate user with email/password."""
    ...
```

### 26.2 Documentation interne

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **README principal** | ðŸ”´ CRITICAL | Setup, architecture overview |
| [x] | **README par module** | ðŸŸ  HIGH | Comme dans ta structure |
| [ ] | **ADRs** | ðŸŸ  HIGH | Architecture Decision Records |
| [x] | **Runbook ops** | ðŸŸ  HIGH | Comment debug, restart, etc. (INCIDENT_RESPONSE.md) |
| [x] | **Security policy** | ðŸ”´ CRITICAL | Comment reporter une vulnÃ©rabilitÃ© (SECURITY.md) |
| [ ] | **Onboarding guide** | ðŸŸ¡ MEDIUM | Pour nouveaux devs |

---

## 27. Compliance & Audit

### 27.1 Audit Trail

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Log tous les events auth** | ðŸ”´ CRITICAL | Login, logout, password change |
| [x] | **Log les accÃ¨s donnÃ©es sensibles** | ðŸ”´ CRITICAL | Read PII |
| [x] | **Log les modifications** | ðŸ”´ CRITICAL | Create, update, delete |
| [x] | **Immutable audit log** | ðŸ”´ CRITICAL | Append-only, pas de DELETE |
| [x] | **Timestamps prÃ©cis** | ðŸ”´ CRITICAL | TIMESTAMPTZ |
| [x] | **IP + User-Agent** | ðŸŸ  HIGH | Context complet |
| [ ] | **Before/After pour updates** | ðŸŸ  HIGH | Diff visible |
| [x] | **Retention 12+ mois** | ðŸ”´ CRITICAL | Selon compliance |

### 27.2 RGPD

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Data inventory** | ðŸ”´ CRITICAL | Quelles donnÃ©es, oÃ¹, pourquoi |
| [N/A] | **Consent tracking** | ðŸ”´ CRITICAL | Non requis - bases lÃ©gales: contrat, intÃ©rÃªt lÃ©gitime, obligation lÃ©gale |
| [x] | **Right to access** | ðŸ”´ CRITICAL | Export des donnÃ©es user |
| [x] | **Right to deletion** | ðŸ”´ CRITICAL | Hard delete possible |
| [x] | **Data portability** | ðŸŸ  HIGH | Export format standard (JSON) |
| [x] | **Breach notification** | ðŸ”´ CRITICAL | Process en place (72h) |
| [N/A] | **DPA with vendors** | ðŸ”´ CRITICAL | Document lÃ©gal - pas du code |

### 27.3 Checklist SÃ©curitÃ© gÃ©nÃ©rale

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [ ] | **Secrets rotation** | ðŸŸ  HIGH | Process pour changer JWT secret, etc. |
| [x] | **Dependency updates** | ðŸ”´ CRITICAL | .github/dependabot.yml |
| [x] | **Security headers** | ðŸ”´ CRITICAL | Voir section 8 (middleware/security_headers.py) |
| [x] | **TLS 1.3** | ðŸ”´ CRITICAL | HTTPS redirect + HSTS |
| [x] | **Vulnerability scanning** | ðŸ”´ CRITICAL | .github/workflows/security.yml |
| [N/A] | **Pen testing** | ðŸŸ  HIGH | Processus externe - Ã  planifier annuellement |
| [x] | **Incident response plan** | ðŸ”´ CRITICAL | Qui fait quoi en cas de breach (INCIDENT_RESPONSE.md) |

---

## 28. Operations

### 28.1 Health Checks

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **GET /health** | ðŸ”´ CRITICAL | Liveness: app rÃ©pond |
| [x] | **GET /ready** | ðŸ”´ CRITICAL | Readiness: DB + Redis OK |
| [x] | **Deep health check** | ðŸŸ  HIGH | Tous les dÃ©pendances |
| [x] | **No auth required** | ðŸ”´ CRITICAL | Pour load balancer |

```python
# âœ… Health endpoints
@app.get("/health", include_in_schema=False)
async def health():
    return {"status": "ok"}

@app.get("/ready", include_in_schema=False)
async def ready(db: DB, redis: Redis):
    errors = []
    
    # Check DB
    try:
        await db.execute(text("SELECT 1"))
    except Exception as e:
        errors.append(f"database: {e}")
    
    # Check Redis
    try:
        await redis.ping()
    except Exception as e:
        errors.append(f"redis: {e}")
    
    if errors:
        return JSONResponse(
            status_code=503,
            content={"status": "error", "errors": errors}
        )
    
    return {"status": "ok"}
```

### 28.2 Graceful Shutdown

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Signal handlers** | ðŸ”´ CRITICAL | SIGTERM, SIGINT |
| [x] | **Drain connections** | ðŸ”´ CRITICAL | Finir requests en cours |
| [x] | **Close DB pool** | ðŸ”´ CRITICAL | Proprement |
| [x] | **Timeout shutdown** | ðŸŸ  HIGH | Force aprÃ¨s 30s |
| [N/A] | **K8s preStop hook** | ðŸŸ  HIGH | Si Kubernetes - infrastructure-specific |

```python
# âœ… Graceful shutdown
import signal
import asyncio
from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await init_db()
    await init_redis()
    
    yield
    
    # Shutdown
    logger.info("Shutting down...")
    await close_db_pool()
    await close_redis()
    logger.info("Shutdown complete")

app = FastAPI(lifespan=lifespan)

# For Docker/K8s
def handle_sigterm(signum, frame):
    logger.info("Received SIGTERM")
    raise SystemExit(0)

signal.signal(signal.SIGTERM, handle_sigterm)
```

### 28.3 Configuration Production

| # | Item | PrioritÃ© | DÃ©tails |
|---|------|----------|---------|
| [x] | **Env vars pour secrets** | ðŸ”´ CRITICAL | validate_secrets() au dÃ©marrage |
| [N/A] | **Secret manager** | ðŸŸ  HIGH | Infrastructure-specific - AWS/Vault selon environnement |
| [x] | **Debug=False** | ðŸ”´ CRITICAL | validate_production_config() bloque si DEBUG=True |
| [x] | **Proper logging level** | ðŸŸ  HIGH | Warning si LOG_LEVEL=DEBUG en prod |
| [N/A] | **Workers selon CPU** | ðŸŸ  HIGH | Infrastructure-specific - docker-compose/K8s config |
| [N/A] | **Memory limits** | ðŸŸ  HIGH | Infrastructure-specific - container config |
| [N/A] | **Resource requests** | ðŸŸ  HIGH | Infrastructure-specific - K8s config |


---

*Document gÃ©nÃ©rÃ© pour review Ã©quipe. Ã€ adapter selon contexte spÃ©cifique.*
